{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMxtPsqcTsSH"
   },
   "source": [
    "# Prediction Model for computing insurance premiums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLG2VTrnTvYL"
   },
   "source": [
    "## 1. Defining the Question\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> To develop a model which will predict insurance premiums that assists insurance companies manage risk and ensure financial stability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XecOwPNorl2W"
   },
   "source": [
    "### a) Specifying the Data Analytic Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ozBnKfehSAw"
   },
   "source": [
    "> There are several challenges that insurance companies face when determining insurance premiums. Insurance companies must assess the risk of an insurance event occurring for each policyholder, taking into account a wide range of factors such as the policyholder's age, gender, medical history, and the type and cost of coverage. This can be a complex and time-consuming process. \n",
    "\n",
    "\n",
    "> **Problem Statement:** \n",
    "The goal of this project is to build a predictive model that can accurately estimate insurance premiums based on a variety of input features.  To train and test our model, we will utilize the Kaggle insurance premium prediction dataset, which contains details on the insurance policy and the policyholder's demographics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4wfHZwQrs-t"
   },
   "source": [
    "### b) Defining the Metric for Success"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "izhfXNR623o4"
   },
   "source": [
    "The project will be considered a success if the developed predictive model is able to explain 80% of the variation of the target variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "a9BPYqunry97"
   },
   "source": [
    "### c) Understanding the context \n",
  
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KMRBJ7zr9HD"
   },
   "source": [
    "### d) Recording the Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9mfUVfi2J4m"
   },
   "source": [
    "1.Collect data: You would need to gather data on the variables that you want to include in your model. These might include variables such as age, location, type of coverage, and any other factors that you think might be relevant to the insurance premiums.\n",
    "\n",
    "2.Clean and preprocess the data: You would need to clean and preprocess the data to ensure that it is in a usable form. This might involve tasks such as removing missing or invalid data, scaling the variables, and encoding categorical variables.\n",
    "\n",
    "3.Split the data into training and test sets: You would need to split the data into a training set and a test set. The training set will be used to fit the linear regression model, while the test set will be used to evaluate the model's performance.\n",
    "\n",
    "4.Fit the linear regression model: You would need to fit a linear regression model to the training data by estimating the values of the coefficients for each predictor variable. You can use various software packages to fit the model, such as R or Python's scikit-learn library.\n",
    "\n",
    "5.Evaluate the model's performance: You can use the test set to evaluate the model's performance by comparing the predicted insurance premiums to the actual premiums. There are several metrics that you can use to assess the model's performance, such as mean squared error and R-squared.\n",
    "\n",
    "6.Use the model to make predictions: Once you have fit and evaluated the model, you can use it to make predictions about the insurance premiums for new customers, based on their values for the predictor variables.\n",
    "\n",
    "7.Conclusions and Reccomendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSGyg6kWsBUl"
   },
   "source": [
    "### e) Data Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUNbvIvnT7ep"
   },
   "source": [
    "## 2. Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xU8pzy_c-QHG"
   },
   "outputs": [],
   "source": [
    "# loading the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJn2KjW-WMlG"
   },
   "outputs": [],
   "source": [
    "# Loading the Data from the source i.e. csv\n",
    "# ---\n",
    "df = pd.read_csv('')\n",
    "# ---\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI3P3YnHUEBk"
   },
   "source": [
    "\n",
    "\n",
    "## 3. Checking the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjSVNwgptHxY"
   },
   "outputs": [],
   "source": [
    "# Determining the no. of records in our dataset\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHhTw5eKWr0n"
   },
   "outputs": [],
   "source": [
    "# Previewing the top of our dataset\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9AzGcZFrIIr"
   },
   "outputs": [],
   "source": [
    "# Previewing the bottom of our dataset\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8-dW4sQWzbc"
   },
   "outputs": [],
   "source": [
    "# Checking whether each column has an appropriate datatype\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckfufNrcUHeH"
   },
   "source": [
    "## 4. External Data Source Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6L4sl_0WXlbg"
   },
   "source": [
    "Making sure your data matches something outside of the dataset is very important. It allows you to ensure that the measurements are roughly in line with what they should be and it serves as a check on what other things might be wrong in your dataset. External validation can often be as simple as checking your data against a single number, as we will do here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XC_g-zKxe-r"
   },
   "source": [
    "### a.Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlBMxEDBUc9B"
   },
   "source": [
    "## 5. Tidying the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5o_bQcT5W3Wz"
   },
   "outputs": [],
   "source": [
    "# Checking for Outliers\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWlukLKUvFQN"
   },
   "outputs": [],
   "source": [
    "# Checking for Anomalies\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvCYb6dgW4yh"
   },
   "outputs": [],
   "source": [
    "# Identifying the Missing Data\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpsDGKZHsf_W"
   },
   "outputs": [],
   "source": [
    "# Dealing with the Missing Data\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-4I__6Os4C5"
   },
   "outputs": [],
   "source": [
    "# More data cleaning procedures\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF2ABPsHUtbZ"
   },
   "source": [
    "## 6. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nnRToniXGDK"
   },
   "outputs": [],
   "source": [
    "# Ploting the bivariate summaries and recording our observations\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UzyQC6kmdBi"
   },
   "outputs": [],
   "source": [
    "# Data Reduction\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTbdjSrhVIiT"
   },
   "source": [
    "## 7. Implementing the Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJLZaRzJXJ3w"
   },
   "outputs": [],
   "source": [
    "# Implementing the Solution\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ2G4ZPDVOXE"
   },
   "source": [
    "## 8. Challenging the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWVGKGuiYMWg"
   },
   "source": [
    "> The easy solution is nice because it is, well, easy, but you should never allow those results to hold the day. You should always be thinking of ways to challenge the results, especially if those results comport with your prior expectation.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3x3SXZ4XT_L"
   },
   "outputs": [],
   "source": [
    "# Reviewing the Solution \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrmHVMVsVS--"
   },
   "source": [
    "## 9. Follow up questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pth2qSWhuBIy"
   },
   "source": [
    "> At this point, we can refine our question or collect new data, all in an iterative process to get at the truth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPQviDmNtta8"
   },
   "source": [
    "### a). Did we have the right data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFHK1CKty7o"
   },
   "source": [
    "### b). Do we need other data to answer our question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSsicSdvt4Zs"
   },
   "source": [
    "### c). Did we have the right question?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a9BPYqunry97",
    "7KMRBJ7zr9HD",
    "zSGyg6kWsBUl",
    "OI3P3YnHUEBk",
    "ckfufNrcUHeH",
    "6XC_g-zKxe-r",
    "FlBMxEDBUc9B",
    "rF2ABPsHUtbZ",
    "vTbdjSrhVIiT",
    "lQ2G4ZPDVOXE",
    "xrmHVMVsVS--",
    "HPQviDmNtta8",
    "qjFHK1CKty7o",
    "HSsicSdvt4Zs"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
